{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7f0d4f-31eb-4b75-93c9-f9283be8c35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecb5f7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAvideos.csv FRvideos.csv INvideos.csv KRvideos.csv RUvideos.csv\n",
      "DEvideos.csv GBvideos.csv JPvideos.csv MXvideos.csv USvideos.csv\n"
     ]
    }
   ],
   "source": [
    "!ls youtube-data/youtube-csv-data/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7be6e15-1bd5-47d5-9919-75b0df35fed6",
   "metadata": {},
   "source": [
    "We will create a handy function that will be used to get the country abbreviations from ```csv``` files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "236dc98f-e8ae-4ef9-9151-3f786b54fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_upper(s):\n",
    "    \"\"\"\n",
    "        Obtaining country abbreviation from a filename.\n",
    "    \"\"\"\n",
    "    upper_chars = \"\"\n",
    "    for char in s:\n",
    "        if char.isupper():\n",
    "            upper_chars += char\n",
    "    return upper_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96960578-83dd-4185-811f-6d3f6d39ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the country abbreviations\n",
    "COUNTRY_ABBREVIATIONS = [only_upper(country) for country in os.listdir(\"./youtube-data/youtube-csv-data/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8141439-c151-433e-91ac-32dafc811fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MX', 'IN', 'DE', 'JP', 'KR', 'CA', 'RU', 'FR', 'US', 'GB']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRY_ABBREVIATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3e4cf94-d3d1-44c7-925b-40044f415aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to manually write the names of them...\n",
    "COUNTRY_NAMES = ['Mexico', 'India', 'Germany', 'Japan', 'South Korea', 'Canada', 'Russia', 'France', 'United States', 'Great Britain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40276d59-3dc9-4c9a-b4aa-7328f511a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#... and define a dictionary that maps abbreviation with the country name\n",
    "COUNTRIES_DICT = dict(zip(COUNTRY_ABBREVIATIONS, COUNTRY_NAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b89599-ba22-4644-9372-e83664050934",
   "metadata": {},
   "source": [
    "Let's sample one of the ```csv``` files at random by creating a function that returns a name of a random ```csv``` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93d78bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_csv():\n",
    "    list_of_csv_files = os.listdir(\"./youtube-data/youtube-csv-data/\")\n",
    "    \n",
    "    #We want to be sure that the csv files are \n",
    "    weights = [1/len(list_of_csv_files) for element in list_of_csv_files]\n",
    "    random_csv_file_name = random.choices(population = list_of_csv_files, weights = weights)[0]\n",
    "    return (random_csv_file_name, only_upper(random_csv_file_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3031b174-ddc0-43bc-92cc-51dd113e083a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_COUNTRY = random_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9045d21d-e4d7-454e-8ed6-95f551436828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first country we are working with is ---> GERMANY <---.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The first country we are working with is ---> {COUNTRIES_DICT[RANDOM_COUNTRY[1]].upper()} <---.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eef6de3-ca0d-4905-b49e-6d5a431179d5",
   "metadata": {},
   "source": [
    "Yes, when you are doing anything that deals with *randomness* inside the code it is a good practise to do ```random.seed()``` for reproducibility, but I've just played with the idea of randomness here to put my personal *touch* inside the code. ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e6e8ae3-00ba-4635-9a8e-af3a0e3e2d2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>title</th>\n",
       "      <th>channel_title</th>\n",
       "      <th>category_id</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>tags</th>\n",
       "      <th>views</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>thumbnail_link</th>\n",
       "      <th>comments_disabled</th>\n",
       "      <th>ratings_disabled</th>\n",
       "      <th>video_error_or_removed</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LgVi6y5QIjM</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Sing zu Ende! | Gesangseinlagen vom Feinsten |...</td>\n",
       "      <td>inscope21</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-11-13T17:08:49.000Z</td>\n",
       "      <td>inscope21|\"sing zu ende\"|\"gesangseinlagen\"|\"ge...</td>\n",
       "      <td>252786</td>\n",
       "      <td>35885</td>\n",
       "      <td>230</td>\n",
       "      <td>1539</td>\n",
       "      <td>https://i.ytimg.com/vi/LgVi6y5QIjM/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Heute gibt es mal wieder ein neues Format... w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bayt7uQith4</td>\n",
       "      <td>17.14.11</td>\n",
       "      <td>Kinder ferngesteuert im Kiosk! Erwachsene abzo...</td>\n",
       "      <td>LUKE! Die Woche und ich</td>\n",
       "      <td>23</td>\n",
       "      <td>2017-11-12T22:30:01.000Z</td>\n",
       "      <td>Kinder|\"ferngesteuert\"|\"Kinder ferngesteuert\"|...</td>\n",
       "      <td>797196</td>\n",
       "      <td>53576</td>\n",
       "      <td>302</td>\n",
       "      <td>1278</td>\n",
       "      <td>https://i.ytimg.com/vi/Bayt7uQith4/default.jpg</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Kinder ferngesteuert! Kinder lassen sich sooo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id trending_date  \\\n",
       "0  LgVi6y5QIjM      17.14.11   \n",
       "1  Bayt7uQith4      17.14.11   \n",
       "\n",
       "                                               title            channel_title  \\\n",
       "0  Sing zu Ende! | Gesangseinlagen vom Feinsten |...                inscope21   \n",
       "1  Kinder ferngesteuert im Kiosk! Erwachsene abzo...  LUKE! Die Woche und ich   \n",
       "\n",
       "   category_id              publish_time  \\\n",
       "0           24  2017-11-13T17:08:49.000Z   \n",
       "1           23  2017-11-12T22:30:01.000Z   \n",
       "\n",
       "                                                tags   views  likes  dislikes  \\\n",
       "0  inscope21|\"sing zu ende\"|\"gesangseinlagen\"|\"ge...  252786  35885       230   \n",
       "1  Kinder|\"ferngesteuert\"|\"Kinder ferngesteuert\"|...  797196  53576       302   \n",
       "\n",
       "   comment_count                                  thumbnail_link  \\\n",
       "0           1539  https://i.ytimg.com/vi/LgVi6y5QIjM/default.jpg   \n",
       "1           1278  https://i.ytimg.com/vi/Bayt7uQith4/default.jpg   \n",
       "\n",
       "   comments_disabled  ratings_disabled  video_error_or_removed  \\\n",
       "0              False             False                   False   \n",
       "1              False             False                   False   \n",
       "\n",
       "                                         description  \n",
       "0  Heute gibt es mal wieder ein neues Format... w...  \n",
       "1  Kinder ferngesteuert! Kinder lassen sich sooo ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Some of the rows contain data which is not utf-8 (ex. South Korean video names), so we have to introducte the workaround via encoding parameter\n",
    "first_country = pd.read_csv(f\"./youtube-data/youtube-csv-data/{RANDOM_COUNTRY[0]}\", encoding='latin-1')\n",
    "first_country.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615f14b5-669b-42b9-a8dc-8ced22a0d142",
   "metadata": {},
   "source": [
    "Now, I'm going to fix my previous logic for choosing columns as I've described in ```README.md``` and ```data-preparation.ipynb``` inside this repo. Apart from that, I'm going to skip the whole step-by-step explanation that I've already done in my ```data-preparation.ipynb```. The main focus will be to fix one of the final ```csv``` files, but the whole logic can be applied to the rest of the files. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d6bb1c-2c76-4fab-84e0-57c9f7bd2f64",
   "metadata": {
    "tags": []
   },
   "source": [
    "# FIX 1\n",
    "```\n",
    "\n",
    "If a video was trending for three days and had 1000 new views every day, and our dataset is:\n",
    "\n",
    "01.01 1000 views\n",
    "\n",
    "02.01 2000 views\n",
    "\n",
    "03.01 3000 views\n",
    "\n",
    "we cannot just add 1000 + 2000 + 3000 to find the total number of views.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6531f90c-3a07-49b8-ad3c-b5a91b6a502b",
   "metadata": {},
   "source": [
    "We should obviosly do ```GROUP BY video_id``` and take the ```MAX(views)``` to fix this.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03fc980-2fb0-420b-b038-d7eadf6f9fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We will import pyspark and create a session\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession, types, functions as F\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"yt_trending_eda\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dc6e1c4-56a8-4dc3-a9b2-fbeac36b21bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_country = spark.read.csv(f\"./youtube-data/youtube-csv-data/{RANDOM_COUNTRY[0]}\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4deba77-313f-4e31-9992-31de51e7a897",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_USED = ['video_id', 'trending_date', 'channel_title', 'category_id', 'views', 'likes', 'dislikes', 'video_error_or_removed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c570b2df-f581-4773-a572-0ef242b2d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtering only videos that are not removed...\n",
    "first_country = first_country.select(COLUMNS_USED).filter(\"video_error_or_removed = False\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5909020-e596-4784-b1c5-5644bcc6fa53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#...and dropping the uneccesary column video_error_or_removed\n",
    "first_country = first_country.drop(\"video_error_or_removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2f7d95a-a244-49e3-a8b8-a2d04a341a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "|   video_id|trending_date|       channel_title|category_id|  views| likes|dislikes|\n",
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "|LgVi6y5QIjM|     17.14.11|           inscope21|         24| 252786| 35885|     230|\n",
      "|Bayt7uQith4|     17.14.11|LUKE! Die Woche u...|         23| 797196| 53576|     302|\n",
      "|1ZAPwfrtAFY|     17.14.11|     LastWeekTonight|         24|2418783| 97190|    6146|\n",
      "|AHtypnRk7JE|     17.14.11|   100SekundenPhysik|         27| 380247| 31821|     458|\n",
      "|ZJ9We4bjcg0|     17.14.11|                rezo|         24| 822213|100684|    2467|\n",
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b9020af-4362-4631-87b0-e8f009019332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: string (nullable = true)\n",
      " |-- views: string (nullable = true)\n",
      " |-- likes: string (nullable = true)\n",
      " |-- dislikes: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a56fdb2b-39cb-48b8-af82-f77da1e51dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- video_id: string (nullable = true)\n",
      " |-- trending_date: string (nullable = true)\n",
      " |-- channel_title: string (nullable = true)\n",
      " |-- category_id: integer (nullable = true)\n",
      " |-- views: integer (nullable = true)\n",
      " |-- likes: integer (nullable = true)\n",
      " |-- dislikes: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#We have to cast the values such that we can later use some of the SQL functionalities\n",
    "first_country = first_country.withColumn(\"category_id\",first_country.category_id.cast(types.IntegerType()))\\\n",
    "                             .withColumn(\"views\",first_country.views.cast(types.IntegerType()))\\\n",
    "                             .withColumn(\"likes\",first_country.likes.cast(types.IntegerType()))\\\n",
    "                             .withColumn(\"dislikes\",first_country.dislikes.cast(types.IntegerType()))\\\n",
    "                             .withColumn(\"channel_title\",first_country.channel_title.cast(types.StringType()))\n",
    "first_country.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b519160-6d73-4516-b1e2-d76fe10ee2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Spark to do FROM statement we have to tell it that the dataframe is a table, so we will create a temporary table\n",
    "first_country.registerTempTable('first_country_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6db13952-e579-465c-b2b3-c63e672e7b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "|   video_id|trending_date|       channel_title|category_id|  views| likes|dislikes|\n",
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "|LgVi6y5QIjM|     17.14.11|           inscope21|         24| 252786| 35885|     230|\n",
      "|Bayt7uQith4|     17.14.11|LUKE! Die Woche u...|         23| 797196| 53576|     302|\n",
      "|1ZAPwfrtAFY|     17.14.11|     LastWeekTonight|         24|2418783| 97190|    6146|\n",
      "|AHtypnRk7JE|     17.14.11|   100SekundenPhysik|         27| 380247| 31821|     458|\n",
      "|ZJ9We4bjcg0|     17.14.11|                rezo|         24| 822213|100684|    2467|\n",
      "|xapGFgWqtg4|     17.14.11|     Die Allestester|         22|  32709|  3093|     296|\n",
      "|EIM7RMe39JY|     17.14.11|          Bodyformus|         23| 308683| 35704|     578|\n",
      "|PaWTaj6Iie0|     17.14.11|          Jay & Arya|         22| 181660| 17998|     169|\n",
      "|GHct2dGNLks|     17.14.11|         TeddyComedy|         23| 369173| 16953|     570|\n",
      "|aZYSFByDGkg|     17.14.11|             WALULIS|          1|  62418|  4749|      44|\n",
      "+-----------+-------------+--------------------+-----------+-------+------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Since Spark has a way of doing operations 'lazily' it wont execute the SQL until we do some action ('tigger the execution' aka Spark Job) like for example show()\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "SELECT *\n",
    "FROM first_country_table\n",
    "\"\"\").show(n=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5535497f-9c78-450a-8596-bec44cf2c301",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:====>                                                    (1 + 11) / 12]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+\n",
      "|   video_id|n_times_trending|\n",
      "+-----------+----------------+\n",
      "|pk0iqFne5eU|               7|\n",
      "|myXi1KMyClc|               6|\n",
      "|zTcNN-zwCog|               5|\n",
      "|3ScQYM1FHrU|               5|\n",
      "|ZJDMWVZta3M|               5|\n",
      "|mnXnLeo54FA|               5|\n",
      "|AdQsDopZfS4|               5|\n",
      "|6ZfuNTqbHE8|               5|\n",
      "|q23qghoF6Nk|               5|\n",
      "|a3YSeVV_HF4|               5|\n",
      "+-----------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Let's quickly find the video that was most days in trending... \n",
    "spark.sql(\"\"\"\n",
    "SELECT video_id, COUNT(1) AS n_times_trending\n",
    "FROM first_country_table\n",
    "GROUP BY video_id\n",
    "ORDER BY n_times_trending DESC\n",
    "\"\"\").show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c578e0a5-f5fb-41fe-9570-ce2388b2ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Depending on the .csv file you get at random, different video_id will be in the top\n",
    "TOP_VIDEO = spark.sql(\"\"\"\n",
    "SELECT video_id, COUNT(1) AS n_times_trending\n",
    "FROM first_country_table\n",
    "GROUP BY video_id\n",
    "ORDER BY n_times_trending DESC\n",
    "\"\"\").first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1905f0d-db03-42d4-bb0a-8d99d56a9251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------+-----+\n",
      "|   video_id|trending_date|  views|likes|\n",
      "+-----------+-------------+-------+-----+\n",
      "|pk0iqFne5eU|     18.08.03|  46622| 1296|\n",
      "|pk0iqFne5eU|     18.09.03| 288392| 4839|\n",
      "|pk0iqFne5eU|     18.10.03| 817531| 9717|\n",
      "|pk0iqFne5eU|     18.11.03|1304894|12763|\n",
      "|pk0iqFne5eU|     18.12.03|1649350|14414|\n",
      "|pk0iqFne5eU|     18.13.03|1806532|15180|\n",
      "|pk0iqFne5eU|     18.14.03|1985594|15947|\n",
      "+-----------+-------------+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#... and see the regression of views and likes for that particular one\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "SELECT video_id, trending_date, views, likes\n",
    "FROM first_country_table\n",
    "WHERE video_id = \"{TOP_VIDEO}\"\n",
    "ORDER BY trending_date ASC\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb49c59-600d-4edb-a2cf-9cbc7126ddc0",
   "metadata": {},
   "source": [
    "Seems that suggested fix makes complete sense. There is an obvious increase in views and/or likes as time progresses. Now, we have to filter those videos that have ```MAX(views)``` but also keeping all of the columns. \n",
    "\n",
    "Simple ```GROUP BY``` wont work because in a ```SELECT``` statement you can use only one column for aggregation and the other one is aggregation function. We need all the columns!\n",
    "\n",
    "The method I will present here is not fully optimized and using ```JOINS``` is expensive, but it will work for this problem. The idea is to create another table from the existing one which will contain unique ```video_id``` and it's corresponding column ```MAX(views)```. Then, we will have two tables which we will ```(SELF)JOIN``` together.\n",
    "\n",
    "Bear in mind that when we do such a ```JOIN``` we will have \"many-to-one\" relationship (```n:1```, where ```n``` represents number of time the video was in trending).\n",
    "\n",
    "If you look at the above example you will see that for each unique ```video_id``` there are ```n``` rows with different number of ```view```s. That is our left table, which we will join with the right table that contains two columns: unique ```video_id``` with it's corresponding ```MAX(views)```. \n",
    "\n",
    "Let's visualize it via one of the examples - video that has been the most times in trending!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc97338a-d763-4954-b347-b8bd50307128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|   video_id|max_views|\n",
      "+-----------+---------+\n",
      "|_UEk3WRixnc|    31500|\n",
      "|bAkEd8r7Nnw|  3300683|\n",
      "|llyuA7q2BkY|     7182|\n",
      "|CXZWqVA-pi8|   120790|\n",
      "|4V38pzhWwCo|  2326516|\n",
      "+-----------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's first define the right table. I will be using Common Table Expressions (CTEs) after this explanation\n",
    "first_country_max_views = first_country.groupBy(\"video_id\").agg(F.max(\"views\").alias(\"max_views\"))\n",
    "first_country_max_views.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "627a8a55-f227-4c4f-9339-fde4904da57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's register it as a table... \n",
    "first_country_max_views.registerTempTable('first_country_max_views_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c47b1f2-8721-4b01-8c20-7e0d9fa53797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|   video_id|max_views|\n",
      "+-----------+---------+\n",
      "|pk0iqFne5eU|  1985594|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#... and test on one of the examples presented above if everything is correct\n",
    "spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM first_country_max_views_table\n",
    "WHERE video_id = \"{TOP_VIDEO}\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a662c730-4a79-481b-8073-97082c5cba0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+-----------+-------+-----+--------+\n",
      "|   video_id|trending_date|channel_title|category_id|  views|likes|dislikes|\n",
      "+-----------+-------------+-------------+-----------+-------+-----+--------+\n",
      "|pk0iqFne5eU|     18.08.03|  Wissenswert|         22|  46622| 1296|     184|\n",
      "|pk0iqFne5eU|     18.09.03|  Wissenswert|         22| 288392| 4839|    2109|\n",
      "|pk0iqFne5eU|     18.10.03|  Wissenswert|         22| 817531| 9717|    5054|\n",
      "|pk0iqFne5eU|     18.11.03|  Wissenswert|         22|1304894|12763|    6751|\n",
      "|pk0iqFne5eU|     18.12.03|  Wissenswert|         22|1649350|14414|    7688|\n",
      "|pk0iqFne5eU|     18.13.03|  Wissenswert|         22|1806532|15180|    8127|\n",
      "|pk0iqFne5eU|     18.14.03|  Wissenswert|         22|1985594|15947|    8652|\n",
      "+-----------+-------------+-------------+-----------+-------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here is how left table...\n",
    "spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM first_country_table\n",
    "WHERE video_id = \"{TOP_VIDEO}\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "354ad1ba-1c2f-43b6-ae6c-fdc686b43f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---------+\n",
      "|   video_id|max_views|\n",
      "+-----------+---------+\n",
      "|pk0iqFne5eU|  1985594|\n",
      "+-----------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#... and right table for this particular example look \n",
    "spark.sql(f\"\"\"\n",
    "SELECT *\n",
    "FROM first_country_max_views_table\n",
    "WHERE video_id = \"{TOP_VIDEO}\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "08ab3c2f-4dd6-422f-b320-4481bbfeb44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "|______VIDEO_ID_______|trending_date|category_id|_______LEFT_TABLE_VIEWS_______|likes|dislikes_0|0_______VIDEO_ID_______|_______RIGHT_TABLE_VIEWS_______|\n",
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "|          pk0iqFne5eU|     18.08.03|         22|                         46622| 1296|       184|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.09.03|         22|                        288392| 4839|      2109|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.10.03|         22|                        817531| 9717|      5054|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.11.03|         22|                       1304894|12763|      6751|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.12.03|         22|                       1649350|14414|      7688|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.13.03|         22|                       1806532|15180|      8127|            pk0iqFne5eU|                        1985594|\n",
      "|          pk0iqFne5eU|     18.14.03|         22|                       1985594|15947|      8652|            pk0iqFne5eU|                        1985594|\n",
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Let's join those two to showcase what've previously described\n",
    "spark.sql(f\"\"\"\n",
    "SELECT t1.video_id AS ______VIDEO_ID_______, t1.trending_date,\n",
    "       t1.category_id, t1.views AS _______LEFT_TABLE_VIEWS_______, t1.likes, t1.dislikes AS dislikes_0,\n",
    "       t2.video_id AS 0_______VIDEO_ID_______, t2.max_views AS _______RIGHT_TABLE_VIEWS_______\n",
    "FROM first_country_table AS t1 INNER JOIN first_country_max_views_table AS t2 ON t1.video_id = t2.video_id\n",
    "WHERE t1.video_id = \"{TOP_VIDEO}\"\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d992d86-60e4-4c87-bac7-8a40650d9e4b",
   "metadata": {},
   "source": [
    "I've aliased the columns and put the additional underscores so you can focus your attention to the thing I've explained: while joining you have n:1 type of join and you see that you have all the permutations for views just for one unique ```video_id```. For those of you who are still struggling with understanding the table joins I've put zeroes in names of two columns (dislikes_**0** and **0**\\_\\_\\_\\_\\_\\_\\_VIDEO_ID\\_______) that represent *fictional* border between two tables (left and right one).  \n",
    "\n",
    "Well, the obvious trick is, while joining, to filter only columns where the number of views in the left table column is equal to the number of views in the right table. You could do the same by using ```likes``` column and still preserve the ```views``` since each day the number of views is increasing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "645147fd-c37a-433b-a555-3b302340eb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "|______VIDEO_ID_______|trending_date|category_id|_______LEFT_TABLE_VIEWS_______|likes|dislikes_0|0_______VIDEO_ID_______|_______RIGHT_TABLE_VIEWS_______|\n",
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "|          pk0iqFne5eU|     18.14.03|         22|                       1985594|15947|      8652|            pk0iqFne5eU|                        1985594|\n",
      "+---------------------+-------------+-----------+------------------------------+-----+----------+-----------------------+-------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#For the above example it would look like this\n",
    "spark.sql(f\"\"\"\n",
    "SELECT t1.video_id AS ______VIDEO_ID_______, t1.trending_date,\n",
    "       t1.category_id, t1.views AS _______LEFT_TABLE_VIEWS_______, t1.likes, t1.dislikes AS dislikes_0,\n",
    "       t2.video_id AS 0_______VIDEO_ID_______, t2.max_views AS _______RIGHT_TABLE_VIEWS_______\n",
    "FROM first_country_table AS t1 INNER JOIN first_country_max_views_table AS t2 ON t1.video_id = t2.video_id\n",
    "WHERE t1.video_id = \"{TOP_VIDEO}\" AND t1.views = t2.max_views\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79fce8aa-90ba-427c-8d8a-4471ed07cc07",
   "metadata": {},
   "source": [
    "Notice that I've added ```AND t1.views = t2.max_views``` into ```WHERE``` clause!\n",
    "\n",
    "Now, imagine that for each unique ```video_id``` in the entire dataset you will repeat the same process! That is what the next ```SQL``` query will do in a nutshell. Also, we will show only the columns from the left table, since the right table is used here as a *helping table* for filtering ```MAX(views)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e833920f-f552-4b94-95f4-8d654d32a64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_country = spark.sql(f\"\"\"\n",
    "\n",
    "WITH helping_table AS (\n",
    "    SELECT video_id, MAX(views) AS max_views\n",
    "    FROM first_country_table\n",
    "    GROUP BY video_id)\n",
    "\n",
    "SELECT t1.video_id AS video_id, t1.channel_title AS channel_title, t1.trending_date AS trending_date,\n",
    "       t1.category_id AS category_id, t1.views AS views, t1.likes AS likes, t1.dislikes AS dislikes\n",
    "FROM first_country_table AS t1 INNER JOIN helping_table AS t2 ON t1.video_id = t2.video_id\n",
    "WHERE t1.views = t2.max_views\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc962872-e3c2-4c21-80cb-3c3c4c391afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-------------+-----------+--------+-------+--------+\n",
      "|   video_id|   channel_title|trending_date|category_id|   views|  likes|dislikes|\n",
      "+-----------+----------------+-------------+-----------+--------+-------+--------+\n",
      "|EIM7RMe39JY|      Bodyformus|     17.14.11|         23|  308683|  35704|     578|\n",
      "|aZYSFByDGkg|         WALULIS|     17.14.11|          1|   62418|   4749|      44|\n",
      "|2hu_evXPpMM|    HerrNewstime|     17.14.11|         24|  228574|  11349|     990|\n",
      "|2Zp-Qm3wJkA|  JP Performance|     17.14.11|          2|  465883|  19928|     216|\n",
      "|3U51cVIqulM|     PlanetKanax|     17.14.11|         23|   99988|   6397|     298|\n",
      "|OKYUtHvgMhc|          VOLKAN|     17.14.11|         24|   37877|   1839|     327|\n",
      "|k_IrAnVSjYE|    Tanja Bremer|     17.14.11|         22|    9413|   1522|      39|\n",
      "|KLxP8VxZjlk|     BJ Magazine|     17.14.11|         25|   91914|     17|      13|\n",
      "|cJx5blgWjDw|           Jarow|     17.14.11|         24|  373833|  21320|    2901|\n",
      "|PK8lHszeXNk|     Cool Mobile|     17.14.11|         22|   27356|    704|      31|\n",
      "|lqJbw2pWZLk|   BangerChannel|     17.14.11|         24|  721888|  45981|     914|\n",
      "|hg0OwRhQpGE|         TopWelt|     17.14.11|         24|  165276|   4085|     197|\n",
      "|XVpDYrjZnuI|o.b. Deutschland|     17.14.11|         26|   38954|   2644|      19|\n",
      "|2Vv-BfVoq4g|      Ed Sheeran|     17.14.11|         10|33523622|1634127|   21082|\n",
      "|TRZPLiLl9HY|             NFL|     17.14.11|         17|  725042|   6620|     294|\n",
      "|zABx5FtO8-8|          di1ara|     17.14.11|         22|   97601|   5364|     560|\n",
      "|WRmrWLOtLGQ|         Klengan|     17.14.11|         24|  109194|  10498|     112|\n",
      "|n1WpP7iowLc|      EminemVEVO|     17.14.11|         10|17158579| 787424|   43420|\n",
      "|qfvMu1vMY1c|             atv|     17.14.11|         24|  716243|   2981|     170|\n",
      "|oWQuB2lVQLc|   Zvezde Granda|     17.14.11|         24|  496192|   1503|     443|\n",
      "+-----------+----------------+-------------+-----------+--------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e08abf-e6f2-446d-81c9-6135cff37605",
   "metadata": {},
   "source": [
    "Currently, I'm looking at a table of trending videos for Germany (DE). Can't miss the thing that one of the trending videos was from ```Zvezde Granda```. There is a fun saying that *there are now more people from Balkans in Germany than the Germans itself*.\n",
    "\n",
    "Allow me this memorable ```SQL``` statement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a778980-54ae-4f5f-a194-7ee1c7992264",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------------+-------------+-----------+------+-----+--------+\n",
      "|   video_id|channel_title|trending_date|category_id| views|likes|dislikes|\n",
      "+-----------+-------------+-------------+-----------+------+-----+--------+\n",
      "|oWQuB2lVQLc|Zvezde Granda|     17.14.11|         24|496192| 1503|     443|\n",
      "|4VqH3Ecx2R0|Zvezde Granda|     17.22.11|         24|744974| 2196|     522|\n",
      "|4sbm8bB583w|Zvezde Granda|     17.28.11|         24|650645| 1912|     492|\n",
      "|8euPVkj4NRo|Zvezde Granda|     17.05.12|         24|455935| 1349|     262|\n",
      "|gP6uGOLeG0M|Zvezde Granda|     17.12.12|         24|603544| 1578|     426|\n",
      "|SGtiZlq4n8k|Zvezde Granda|     17.19.12|         24|486761| 1499|     418|\n",
      "|gn4BHh_I5Tg|Zvezde Granda|     17.26.12|         24|476073| 1633|     408|\n",
      "|pcfyR8a96G8|Zvezde Granda|     18.02.01|         24|318258| 1121|     277|\n",
      "|xcoDlq2AiOU|Zvezde Granda|     18.09.01|         24|413322| 1382|     344|\n",
      "|gU492TPrm8g|Zvezde Granda|     18.16.01|         24|507564| 1385|     418|\n",
      "|JpjfAYrZxXU|Zvezde Granda|     18.23.01|         24|453111| 1267|     460|\n",
      "|-pL9wztMd3A|Zvezde Granda|     18.30.01|         24|387634| 1180|     441|\n",
      "|PT5fXUNktSk|Zvezde Granda|     18.06.02|         24|393273| 1120|     362|\n",
      "|gZEvwZay-8Y|Zvezde Granda|     18.13.02|         24|339113| 1164|     343|\n",
      "|vWR4KJeOC9c|Zvezde Granda|     18.20.02|         24|415199| 1303|     379|\n",
      "|0HaZxFJt8z0|Zvezde Granda|     18.27.02|         24|464518| 1310|     646|\n",
      "|e2LJYeBzulY|Zvezde Granda|     18.06.03|         24|412675| 1239|     367|\n",
      "|T7RKuvO5n88|Zvezde Granda|     18.14.03|         24|428867| 1532|     401|\n",
      "|IB7bvNTYsrM|Zvezde Granda|     18.19.03|         24|306192|  825|     300|\n",
      "|d8Z747JzCtM|Zvezde Granda|     18.26.03|         24|283862|  910|     258|\n",
      "+-----------+-------------+-------------+-----------+------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#I don't know if there is Zvezde Granda in other countries so bear in mind that this might return empty table!\n",
    "first_country.registerTempTable('first_country_de_table')\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM first_country_de_table\n",
    "WHERE channel_title = 'Zvezde Granda'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4cd76b8b-d3bf-4545-a009-052e39b561c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Spark says \"only showing top 20 rows\":\n",
    "spark.sql(\"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM first_country_de_table\n",
    "WHERE channel_title = 'Zvezde Granda'\n",
    "\"\"\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f85096-849f-44d0-983a-3300eb3d5243",
   "metadata": {},
   "source": [
    "**31 times** music from famous ```Zvezde Granda``` (Serbia) were trending in Germany! Let's see if there were times where it was the most viewed video in trending!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a6512ca-60ff-4660-ae4c-7502af94a99d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+-------------+-----+-----+--------+\n",
      "|video_id|channel_title|trending_date|views|likes|dislikes|\n",
      "+--------+-------------+-------------+-----+-----+--------+\n",
      "+--------+-------------+-------------+-----+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "\n",
    "WITH sinan_sakic AS (\n",
    "    SELECT trending_date, MAX(views) AS views\n",
    "    FROM first_country_de_table\n",
    "    GROUP BY trending_date)\n",
    "\n",
    "SELECT t1.video_id AS video_id, t1.channel_title AS channel_title, t1.trending_date AS trending_date, t1.views AS views, t1.likes AS likes, t1.dislikes AS dislikes\n",
    "FROM first_country_de_table AS t1 INNER JOIN sinan_sakic AS t2 ON t1.trending_date = t2.trending_date\n",
    "WHERE t1.views = t2.views AND t1.channel_title = 'Zvezde Granda'\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b1687-26e5-4587-aa3c-5a93865243a6",
   "metadata": {},
   "source": [
    "I think the ```SQL``` logic is broken.... ;)\n",
    "\n",
    "Enough of the fun part! Let's drop the ```trending_date``` column, add the column ```country``` that will represent the country abbreviation and finally merge this table with the corresponding ```JSON``` file to get the ```category_name``` based on the ```category_id```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bfd7d74-ca56-4522-96d1-a43ad5c4ce77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+-----------+--------+-------+--------+-------+\n",
      "|   video_id|   channel_title|category_id|   views|  likes|dislikes|country|\n",
      "+-----------+----------------+-----------+--------+-------+--------+-------+\n",
      "|EIM7RMe39JY|      Bodyformus|         23|  308683|  35704|     578|     DE|\n",
      "|aZYSFByDGkg|         WALULIS|          1|   62418|   4749|      44|     DE|\n",
      "|2hu_evXPpMM|    HerrNewstime|         24|  228574|  11349|     990|     DE|\n",
      "|2Zp-Qm3wJkA|  JP Performance|          2|  465883|  19928|     216|     DE|\n",
      "|3U51cVIqulM|     PlanetKanax|         23|   99988|   6397|     298|     DE|\n",
      "|OKYUtHvgMhc|          VOLKAN|         24|   37877|   1839|     327|     DE|\n",
      "|k_IrAnVSjYE|    Tanja Bremer|         22|    9413|   1522|      39|     DE|\n",
      "|KLxP8VxZjlk|     BJ Magazine|         25|   91914|     17|      13|     DE|\n",
      "|cJx5blgWjDw|           Jarow|         24|  373833|  21320|    2901|     DE|\n",
      "|PK8lHszeXNk|     Cool Mobile|         22|   27356|    704|      31|     DE|\n",
      "|lqJbw2pWZLk|   BangerChannel|         24|  721888|  45981|     914|     DE|\n",
      "|hg0OwRhQpGE|         TopWelt|         24|  165276|   4085|     197|     DE|\n",
      "|XVpDYrjZnuI|o.b. Deutschland|         26|   38954|   2644|      19|     DE|\n",
      "|2Vv-BfVoq4g|      Ed Sheeran|         10|33523622|1634127|   21082|     DE|\n",
      "|TRZPLiLl9HY|             NFL|         17|  725042|   6620|     294|     DE|\n",
      "|zABx5FtO8-8|          di1ara|         22|   97601|   5364|     560|     DE|\n",
      "|WRmrWLOtLGQ|         Klengan|         24|  109194|  10498|     112|     DE|\n",
      "|n1WpP7iowLc|      EminemVEVO|         10|17158579| 787424|   43420|     DE|\n",
      "|qfvMu1vMY1c|             atv|         24|  716243|   2981|     170|     DE|\n",
      "|oWQuB2lVQLc|   Zvezde Granda|         24|  496192|   1503|     443|     DE|\n",
      "+-----------+----------------+-----------+--------+-------+--------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country = first_country.drop('trending_date').select('*', F.lit(f'{RANDOM_COUNTRY[1]}').alias(\"country\"))\n",
    "first_country.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "43a253f7-77aa-4845-8cf7-8aa54077fc21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='first_country_de_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_max_views_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finally, let's register it as a new table (overwrite it on the existing one!)\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ea21b9b1-f7d9-4ed4-ba12-4732bc61f54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"first_country_table\")\n",
    "first_country.registerTempTable('first_country_table')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8812190f-a916-4b03-a11a-a2c333caf0b3",
   "metadata": {},
   "source": [
    "# Accesing JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0149f41a-4d8c-4ddc-8fd7-b15be732a56f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CA_category_id.json GB_category_id.json KR_category_id.json US_category_id.json\n",
      "DE_category_id.json IN_category_id.json MX_category_id.json\n",
      "FR_category_id.json JP_category_id.json RU_category_id.json\n"
     ]
    }
   ],
   "source": [
    "!ls youtube-data/youtube-json-data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "68825dcd-5233-4ed3-88e0-6c1d63c6bd18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|                etag|               items|                kind|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|\"ld9biNPKjAjgjV7E...|[{\"ld9biNPKjAjgjV...|youtube#videoCate...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read: https://analyticshut.com/reading-json-data-in-spark/\n",
    "# and https://medium.com/expedia-group-tech/working-with-json-in-apache-spark-1ecf553c2a8c\n",
    "first_country_json = spark.read.option(\"multiline\",\"true\").json(f\"./youtube-data/youtube-json-data/{RANDOM_COUNTRY[1]}_category_id.json\")\n",
    "first_country_json.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "652f0a40-42ba-44b3-b216-070c6f7fc376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- etag: string (nullable = true)\n",
      " |-- items: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- etag: string (nullable = true)\n",
      " |    |    |-- id: string (nullable = true)\n",
      " |    |    |-- kind: string (nullable = true)\n",
      " |    |    |-- snippet: struct (nullable = true)\n",
      " |    |    |    |-- assignable: boolean (nullable = true)\n",
      " |    |    |    |-- channelId: string (nullable = true)\n",
      " |    |    |    |-- title: string (nullable = true)\n",
      " |-- kind: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country_json.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fdb985de-1053-436a-abad-b4512e04df49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kind': 'youtube#videoCategory',\n",
       " 'etag': '\"ld9biNPKjAjgjV7EZ4EKeEGrhao/Xy1mB4_yLrHy_BmKmPBggty2mZQ\"',\n",
       " 'id': '1',\n",
       " 'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
       "  'title': 'Film & Animation',\n",
       "  'assignable': True}}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Snippet of a JSON file\n",
    "{'kind': 'youtube#videoCategory',\n",
    " 'etag': '\"ld9biNPKjAjgjV7EZ4EKeEGrhao/Xy1mB4_yLrHy_BmKmPBggty2mZQ\"',\n",
    " 'id': '1',\n",
    " 'snippet': {'channelId': 'UCBR8-60-B28hp2BmDPdntcQ',\n",
    "  'title': 'Film & Animation',\n",
    "  'assignable': True}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "513ab9db-580a-4136-a299-d04496a8c664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|               title|\n",
      "+--------------------+--------------------+\n",
      "|[1, 2, 10, 15, 17...|[Film & Animation...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country_json.select(\"items.id\", \"items.snippet.title\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f56426d-4c2d-4fb8-b792-4f6908426058",
   "metadata": {},
   "source": [
    "Let's explore those two columns more clearly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0e5147f7-3b20-471f-b407-6d7723e226ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|cat_id|\n",
      "+------+\n",
      "|     1|\n",
      "|     2|\n",
      "|    10|\n",
      "|    15|\n",
      "|    17|\n",
      "|    18|\n",
      "|    19|\n",
      "|    20|\n",
      "|    21|\n",
      "|    22|\n",
      "|    23|\n",
      "|    24|\n",
      "|    25|\n",
      "|    26|\n",
      "|    27|\n",
      "|    28|\n",
      "|    30|\n",
      "|    31|\n",
      "|    32|\n",
      "|    33|\n",
      "+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country_json.select(F.explode(\"items.id\").alias(\"cat_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "587ba003-ca3c-4f9e-9945-68ad1776f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            category|\n",
      "+--------------------+\n",
      "|    Film & Animation|\n",
      "|    Autos & Vehicles|\n",
      "|               Music|\n",
      "|      Pets & Animals|\n",
      "|              Sports|\n",
      "|        Short Movies|\n",
      "|     Travel & Events|\n",
      "|              Gaming|\n",
      "|       Videoblogging|\n",
      "|      People & Blogs|\n",
      "|              Comedy|\n",
      "|       Entertainment|\n",
      "|     News & Politics|\n",
      "|       Howto & Style|\n",
      "|           Education|\n",
      "|Science & Technology|\n",
      "|              Movies|\n",
      "|     Anime/Animation|\n",
      "|    Action/Adventure|\n",
      "|            Classics|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country_json.select(F.explode(\"items.snippet.title\").alias(\"category\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "63711c9e-8d62-4d3a-8313-b0c50570cfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|                  id|               title|\n",
      "+--------------------+--------------------+\n",
      "|[1, 2, 10, 15, 17...|[Film & Animation...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_country_json.select(\"items.id\", \"items.snippet.title\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d1c28c62-870c-4a45-897b-1eab939f6488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|cat_id|            category|\n",
      "+------+--------------------+\n",
      "|     1|    Film & Animation|\n",
      "|     2|    Autos & Vehicles|\n",
      "|    10|               Music|\n",
      "|    15|      Pets & Animals|\n",
      "|    17|              Sports|\n",
      "|    18|        Short Movies|\n",
      "|    19|     Travel & Events|\n",
      "|    20|              Gaming|\n",
      "|    21|       Videoblogging|\n",
      "|    22|      People & Blogs|\n",
      "|    23|              Comedy|\n",
      "|    24|       Entertainment|\n",
      "|    25|     News & Politics|\n",
      "|    26|       Howto & Style|\n",
      "|    27|           Education|\n",
      "|    28|Science & Technology|\n",
      "|    30|              Movies|\n",
      "|    31|     Anime/Animation|\n",
      "|    32|    Action/Adventure|\n",
      "|    33|            Classics|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Here is a solution on how to 'explode' multiple columns and make a table out of it\n",
    "#https://stackoverflow.com/questions/51082758/how-to-explode-multiple-columns-of-a-dataframe-in-pyspark\n",
    "first_country_json.selectExpr('inline(arrays_zip(items.id,items.snippet.title))') \\\n",
    "                  .withColumnRenamed(\"0\", \"cat_id\") \\\n",
    "                  .withColumnRenamed(\"1\", \"category\") \\\n",
    "                  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4a3c2737-c287-40d3-badb-9cb7ea6fcb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's save it as a temp table\n",
    "first_country_json = first_country_json.selectExpr('inline(arrays_zip(items.id,items.snippet.title))') \\\n",
    "                  .withColumnRenamed(\"0\", \"cat_id\") \\\n",
    "                  .withColumnRenamed(\"1\", \"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a277eb09-d6ab-422f-a6fd-9fc0071c5813",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_country_json.registerTempTable('first_country_json_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c93e6547-e224-4278-b3ce-60fd7caab4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='first_country_de_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_json_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_max_views_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's clear up the unused Temporary Tables (Views)\n",
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a13cafde-f4f8-41de-9825-5cf156f81eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.dropTempView(\"first_country_de_table\")\n",
    "spark.catalog.dropTempView(\"first_country_max_views_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fea4b1e1-edf7-427d-9404-ee9a942e481f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table(name='first_country_json_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True),\n",
       " Table(name='first_country_table', database=None, description=None, tableType='TEMPORARY', isTemporary=True)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.catalog.listTables()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e696545-54db-44bb-9aed-31dbaad16f7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# JOINING CSV AND JSON FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "beeba040-9490-4008-a503-26c939d09aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+--------+-------+--------+-------+----------------+\n",
      "|   video_id|   channel_title|   views|  likes|dislikes|country|        category|\n",
      "+-----------+----------------+--------+-------+--------+-------+----------------+\n",
      "|EIM7RMe39JY|      Bodyformus|  308683|  35704|     578|     DE|          Comedy|\n",
      "|aZYSFByDGkg|         WALULIS|   62418|   4749|      44|     DE|Film & Animation|\n",
      "|2hu_evXPpMM|    HerrNewstime|  228574|  11349|     990|     DE|   Entertainment|\n",
      "|2Zp-Qm3wJkA|  JP Performance|  465883|  19928|     216|     DE|Autos & Vehicles|\n",
      "|3U51cVIqulM|     PlanetKanax|   99988|   6397|     298|     DE|          Comedy|\n",
      "|OKYUtHvgMhc|          VOLKAN|   37877|   1839|     327|     DE|   Entertainment|\n",
      "|k_IrAnVSjYE|    Tanja Bremer|    9413|   1522|      39|     DE|  People & Blogs|\n",
      "|KLxP8VxZjlk|     BJ Magazine|   91914|     17|      13|     DE| News & Politics|\n",
      "|cJx5blgWjDw|           Jarow|  373833|  21320|    2901|     DE|   Entertainment|\n",
      "|PK8lHszeXNk|     Cool Mobile|   27356|    704|      31|     DE|  People & Blogs|\n",
      "|lqJbw2pWZLk|   BangerChannel|  721888|  45981|     914|     DE|   Entertainment|\n",
      "|hg0OwRhQpGE|         TopWelt|  165276|   4085|     197|     DE|   Entertainment|\n",
      "|XVpDYrjZnuI|o.b. Deutschland|   38954|   2644|      19|     DE|   Howto & Style|\n",
      "|2Vv-BfVoq4g|      Ed Sheeran|33523622|1634127|   21082|     DE|           Music|\n",
      "|TRZPLiLl9HY|             NFL|  725042|   6620|     294|     DE|          Sports|\n",
      "|zABx5FtO8-8|          di1ara|   97601|   5364|     560|     DE|  People & Blogs|\n",
      "|WRmrWLOtLGQ|         Klengan|  109194|  10498|     112|     DE|   Entertainment|\n",
      "|n1WpP7iowLc|      EminemVEVO|17158579| 787424|   43420|     DE|           Music|\n",
      "|qfvMu1vMY1c|             atv|  716243|   2981|     170|     DE|   Entertainment|\n",
      "|oWQuB2lVQLc|   Zvezde Granda|  496192|   1503|     443|     DE|   Entertainment|\n",
      "+-----------+----------------+--------+-------+--------+-------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#As I've explained in the data-preparation.ipynb we will use LEFT JOIN in case that there might be possibility of API collecting a wrong id that doesn't exist\n",
    "#in the accompanying JSON file\n",
    "\n",
    "first_country_combined = spark.sql(\"\"\"\n",
    "\n",
    "SELECT *\n",
    "FROM first_country_table AS t1 LEFT JOIN first_country_json_table AS t2 ON t1.category_id = t2.cat_id\n",
    "\"\"\").drop(\"category_id\", \"cat_id\")\n",
    "\n",
    "first_country_combined.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bca32635-a0a2-4364-a429-4c6c7a543ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_COUNTRY[1].lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c418f202-f6d3-4bf3-a0a6-ace029da00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, we will export it:\n",
    "first_country_combined.write.mode('overwrite').csv(f'./exported-data-spark/{RANDOM_COUNTRY[1].lower()}_videos.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889560f1-0dda-4f8a-a442-df6ea49ee8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf4cfd6-baa3-4ad1-9c6b-6362db64ad17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb42414e-9059-45b8-8fc9-48a4be7ceb57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
